Z.prob1 = prod(Z.dens1) * pi/ (prod(Z.dens1) * pi + prod(Z.dens0) * (1-pi))
Z.dens0
Z.dens1
prod(Z.dens1)
(prod(Z.dens1)
)
Z.prob1 = prod(Z.dens1) * pi/ (prod(Z.dens1) * pi + prod(Z.dens0) * (1-pi))
Z.prob1
pi
pi = .5
w=.5
Z.prob1 = prod(Z.dens1) * w/ (prod(Z.dens1) * w + prod(Z.dens0) * (1-w))
Z.prob1
prod(Z.dens1)
Z = sample(c(0,1),1,prob = c(1-Z.prob1,Z.prob1))
Z
gamma
source("~/Documents/Research/multiple_shrinkage/replication_code/simulation.R", echo=TRUE)
setwd("~/Documents/Research/multiple_shrinkage/replication_code")
source("~/Documents/Research/multiple_shrinkage/replication_code/simulation.R", echo=TRUE)
source("~/Documents/Research/multiple_shrinkage/replication_code/simulation.R", echo=TRUE)
#stop cluster
stopCluster(cl)
g.ind
[n.ind]
n.ind
p1.ind
# get changing params
g = gs[g.ind]
p1 = p1s[p1.ind]
N = p1*p2*Ns[n.ind] + 1
# calculate final params
p = p1*p2
ns = rep(N,g)
# storage helper
nopool.collect = array(NA,dim=c(p,p,g))
###########################
## get true covariance
Sig.true = Sigj.true = list()
set.seed(123)
if (data.type == "homo, sep"){
RHO = .7
V1.true = eye(p1)*(1-RHO) + RHO
RHO = .3
V2.true = eye(p2)*(1-RHO) + RHO
V.inv.true = kronecker((V2.true),(V1.true))
for(i in 1:g){
Sig.true[[i]] = V.inv.true
}
} else if (data.type == "hetero, sep"){
for(i in 1:g){
RHO = sample(seq(from = .35,to =.99,length.out = 15),1)
V1.true = eye(p1)*(1-RHO) + RHO
RHO = sample(seq(from = .35,to =.99,length.out = 15),1)
V2.true = eye(p2)*(1-RHO) + RHO
V.inv.true = kronecker((V2.true),(V1.true))
Sig.true[[i]] = V.inv.true
}
} else if (data.type == "near homo, not sep") {
V1.true = zeros(p1)
V2.true = zeros(p2)
V0.true = (rcovmat(p))
for(i in 1:g){
Sig.true[[i]] = V0.true + rcovmat(p,.1)
}
} else if (data.type == "hetero, not sep") {
for(i in 1:g){
RHO = sample(seq(from = .35,to =.99,length.out = 15),1)
Sig.true[[i]] = eye(p)*(1-RHO) + RHO
}
} else if (data.type == "homo, not sep") {
RHO = .7
V0.true = eye(p)*(1-RHO) + RHO
for(i in 1:g){
Sig.true[[i]] = V0.true
}
}
set.seed(Sys.time())
#setup parallel backend to use many processors
cores=detectCores()
cl <- makeCluster(cores[1] - 1)  # dont overload your computer
registerDoParallel(cl)
#stop cluster
stopCluster(cl)
output = list()
###########################
## sim fake data
set.seed(sim.ind)
Y.list = list()
sim.ind=1
###########################
## sim fake data
set.seed(sim.ind)
Y.list = list()
for(i in 1:g){
Y.list[[i]] = matrix(rnorm(ns[i]*p),nrow=ns[i]) %*% chol(Sig.true[[i]])
}
set.seed(Sys.time())
## remove mean
de.mean = function(YY){
nn = nrow(YY)
one.nxn = matrix(rep(1,nn*nn),ncol=nn)
YY.o = (eye(nn) - one.nxn/nn) %*% YY
return(YY.o)
}
Y.list = lapply(Y.list,de.mean)
## reformat to matrix with group
temp = lbind(Y.list)
group = temp$group
Y.matrix = temp$mat
## reformat to p1xp2xN array
N = sum(ns)
Y.array = array(NA,dim=c(p1,p2,N))
for ( j in 1:N){
Y.array[,,j] = matrix(Y.matrix[j,],nrow = p1,ncol = p2,byrow = F)
}
###########################
## run GS for multiple shrinkage
model = multiple_shrinkage_GS(S,burnin,thin)
# priors on layer 3 hetero kronecker Wisharts
S1 = eye(p1); S1.inv = solve(S1)
S2 = eye(p2); S2.inv= solve(S2)
eta1 = p1 + 2; eta2 = p2 + 2
# priors on layer 4 homo kronecker Wisharts
N1 = eye(p1)
N2 = eye(p2)
xi1 = p1 + 2; xi2 =  p2 + 2
# domain for degrees of freedom
df.domain = c((p+2):(p+50)); DFD = length(df.domain)
## intialize values for GS
# level 1
U = lapply(1:g,function(j)matrix(rnorm(ns[j]*p),ncol=p))
Sig = Sig.inv = Psi = Psi.inv = lapply(1:g,function(j)eye(p))
# level 2 and 3
nu0 = p+2
gam = p+2
V0 = V0.inv = eye(p)
V1 = lapply(1:g,function(j)rwish(S1,eta1))
V1.inv = lapply(V1,solve)
V2 = lapply(1:g,function(j)rwish(S2,eta2))
V2.inv = lapply(V2,solve)
# level 4
K1 = K1.inv = eye(p1)
K2 = K2.inv = eye(p2)
S0 = S0.inv = eye(p)
eta0 = p+2
w = rep(.5,g)
## sample (gamma, {Sigj}) jointly
# sample gamma; Sigjs are marginalized out
d.sig = matrix(NA,nrow=g,ncol=DFD)
# helpers
acc = rep(0,g)
## sample (gamma, {Sigj}) jointly
# sample gamma; Sigjs are marginalized out
d.sig = matrix(NA,nrow=g,ncol=DFD)
for ( j in 1:g ){
Vj.inv = kronecker(V2.inv[[j]],V1.inv[[j]])
Vj = kronecker(V2[[j]],V1[[j]])
d.sig[j,] = sapply(df.domain,function(k)
dmatT.propto(Y.list[[j]],k-p+1,w[j]^(1/2)*U[[j]],(1-w[j]) * Vj * (k-p-1),k,
Omega.inv = Vj.inv / (k-p-1) / (1-w[j]) ) )
}
d.sig = apply(d.sig,2,sum)
d.sig = exp(d.sig-max(d.sig))
probs = d.sig/sum(d.sig)
gam = sample(df.domain,size = 1,prob = probs)
# sample Sigj
for( j in 1:g ){
V = kronecker(V2[[j]],V1[[j]])
Y.tilde = Y.list[[j]] - w[j]^(1/2)*U[[j]]
M = solve(V * (gam - p - 1) + t(Y.tilde) %*% Y.tilde / (1-w[j]))
Sig.inv[[j]] = rwish(M,gam+ns[j]-1)
Sig[[j]] = solve(Sig.inv[[j]])
}
## sample (w,{Uj}) jointly
# sample w; U is marginalized out
# propose w.star from symmetric proposal
if ( single.weight == 1 ){
w.hat = w[1]
w.star = MH_sym_proposal_01(w.hat, mh.delta)
# compute acceptance ratio, joint distn' of all variables and w; U is marginalized out
d.star = sapply(1:g,function(j)dmatnorm(Y.list[[j]],0,
eye(ns[j]),
w.star * Psi[[j]] + (1-w.star) * Sig[[j]],
TRUE))
d.s = sapply(1:g,function(j)dmatnorm(Y.list[[j]],0,
eye(ns[j]),
w.hat * Psi[[j]] + (1-w.hat) * Sig[[j]],
TRUE))
R = sum(d.star) - sum(d.s) +
dbeta(w.star,1/2,1/2,log=T) - dbeta(w.hat,1/2,1/2,log=T)
# if u<r, set w to be w.star
if (log(runif(1))<R){
w = rep(w.star,g)
acc[1] = acc[1] + 1
}
} else {
for ( j in 1:g ){
wj.hat = w[j]
wj.star = MH_sym_proposal_01(wj.hat, mh.delta)
# compute acceptance ratio, joint distn' of all variables and w; U is marginalized out
d.star = dmatnorm(Y.list[[j]],0,
eye(ns[j]),
wj.star * Psi[[j]] + (1-wj.star) * Sig[[j]],
TRUE)
d.s = dmatnorm(Y.list[[j]],0,
eye(ns[j]),
wj.hat * Psi[[j]] + (1-wj.hat) * Sig[[j]],
TRUE)
R = (d.star) - (d.s) +
dbeta(wj.star,1/2,1/2,log=T) - dbeta(wj.hat,1/2,1/2,log=T)
# if u<r, set wj to be wj.star
if (log(runif(1))<R){
w[j] = wj.star
acc[j] = acc[j] + 1
}
}
}
single.weight=1
## sample (w,{Uj}) jointly
# sample w; U is marginalized out
# propose w.star from symmetric proposal
if ( single.weight == 1 ){
w.hat = w[1]
w.star = MH_sym_proposal_01(w.hat, mh.delta)
# compute acceptance ratio, joint distn' of all variables and w; U is marginalized out
d.star = sapply(1:g,function(j)dmatnorm(Y.list[[j]],0,
eye(ns[j]),
w.star * Psi[[j]] + (1-w.star) * Sig[[j]],
TRUE))
d.s = sapply(1:g,function(j)dmatnorm(Y.list[[j]],0,
eye(ns[j]),
w.hat * Psi[[j]] + (1-w.hat) * Sig[[j]],
TRUE))
R = sum(d.star) - sum(d.s) +
dbeta(w.star,1/2,1/2,log=T) - dbeta(w.hat,1/2,1/2,log=T)
# if u<r, set w to be w.star
if (log(runif(1))<R){
w = rep(w.star,g)
acc[1] = acc[1] + 1
}
} else {
for ( j in 1:g ){
wj.hat = w[j]
wj.star = MH_sym_proposal_01(wj.hat, mh.delta)
# compute acceptance ratio, joint distn' of all variables and w; U is marginalized out
d.star = dmatnorm(Y.list[[j]],0,
eye(ns[j]),
wj.star * Psi[[j]] + (1-wj.star) * Sig[[j]],
TRUE)
d.s = dmatnorm(Y.list[[j]],0,
eye(ns[j]),
wj.hat * Psi[[j]] + (1-wj.hat) * Sig[[j]],
TRUE)
R = (d.star) - (d.s) +
dbeta(wj.star,1/2,1/2,log=T) - dbeta(wj.hat,1/2,1/2,log=T)
# if u<r, set wj to be wj.star
if (log(runif(1))<R){
w[j] = wj.star
acc[j] = acc[j] + 1
}
}
}
mh.delta=.1
## sample (w,{Uj}) jointly
# sample w; U is marginalized out
# propose w.star from symmetric proposal
if ( single.weight == 1 ){
w.hat = w[1]
w.star = MH_sym_proposal_01(w.hat, mh.delta)
# compute acceptance ratio, joint distn' of all variables and w; U is marginalized out
d.star = sapply(1:g,function(j)dmatnorm(Y.list[[j]],0,
eye(ns[j]),
w.star * Psi[[j]] + (1-w.star) * Sig[[j]],
TRUE))
d.s = sapply(1:g,function(j)dmatnorm(Y.list[[j]],0,
eye(ns[j]),
w.hat * Psi[[j]] + (1-w.hat) * Sig[[j]],
TRUE))
R = sum(d.star) - sum(d.s) +
dbeta(w.star,1/2,1/2,log=T) - dbeta(w.hat,1/2,1/2,log=T)
# if u<r, set w to be w.star
if (log(runif(1))<R){
w = rep(w.star,g)
acc[1] = acc[1] + 1
}
} else {
for ( j in 1:g ){
wj.hat = w[j]
wj.star = MH_sym_proposal_01(wj.hat, mh.delta)
# compute acceptance ratio, joint distn' of all variables and w; U is marginalized out
d.star = dmatnorm(Y.list[[j]],0,
eye(ns[j]),
wj.star * Psi[[j]] + (1-wj.star) * Sig[[j]],
TRUE)
d.s = dmatnorm(Y.list[[j]],0,
eye(ns[j]),
wj.hat * Psi[[j]] + (1-wj.hat) * Sig[[j]],
TRUE)
R = (d.star) - (d.s) +
dbeta(wj.star,1/2,1/2,log=T) - dbeta(wj.hat,1/2,1/2,log=T)
# if u<r, set wj to be wj.star
if (log(runif(1))<R){
w[j] = wj.star
acc[j] = acc[j] + 1
}
}
}
w.hat = w[1]
w.star = MH_sym_proposal_01(w.hat, mh.delta)
# compute acceptance ratio, joint distn' of all variables and w; U is marginalized out
d.star = sapply(1:g,function(j)dmatnorm(Y.list[[j]],0,
eye(ns[j]),
w.star * Psi[[j]] + (1-w.star) * Sig[[j]],
TRUE))
Y.list
eye(ns[j])
w.star
Psi
w.star
Sig
source("~/Documents/Research/multiple_shrinkage/replication_code/simulation.R", echo=TRUE)
#stop cluster
stopCluster(cl)
source("~/Documents/Research/multiple_shrinkage/replication_code/simulation.R", echo=TRUE)
#stop cluster
stopCluster(cl)
source("~/Documents/Research/multiple_shrinkage/replication_code/simulation.R", echo=TRUE)
#stop cluster
stopCluster(cl)
###########################
## sim fake data
set.seed(sim.ind)
Y.list = list()
for(i in 1:g){
Y.list[[i]] = matrix(rnorm(ns[i]*p),nrow=ns[i]) %*% chol(Sig.true[[i]])
}
set.seed(Sys.time())
## remove mean
de.mean = function(YY){
nn = nrow(YY)
one.nxn = matrix(rep(1,nn*nn),ncol=nn)
YY.o = (eye(nn) - one.nxn/nn) %*% YY
return(YY.o)
}
Y.list = lapply(Y.list,de.mean)
## reformat to matrix with group
temp = lbind(Y.list)
group = temp$group
Y.matrix = temp$mat
## reformat to p1xp2xN array
N = sum(ns)
Y.array = array(NA,dim=c(p1,p2,N))
for ( j in 1:N){
Y.array[,,j] = matrix(Y.matrix[j,],nrow = p1,ncol = p2,byrow = F)
}
###########################
## run GS for multiple shrinkage
model = multiple_shrinkage_GS(S,burnin,thin,
save_all = 0)
## summarise output and save
output$MS.pm = array(colMeans(model$Sig + model$Psi),dim = c(p,p,g))
output = list()
## summarise output and save
output$MS.pm = array(colMeans(model$Sig + model$Psi),dim = c(p,p,g))
MS.stein.pm.temp = array(colMeans(model$cov.inv),dim = c(p,p,g))
MS.stein.pm.temp.inv = array(NA,dim=c(p,p,g))
for ( k in 1:g ){
MS.stein.pm.temp.inv[,,k] = solve(MS.stein.pm.temp[,,k])
}
output$MS.stein.pm = MS.stein.pm.temp.inv
###########################
## no pooling- shrink to decent prior/regularization
df = p + 4
for ( j in 1:g){
nopool.collect[,,j] = cov.shrink.pm(sumsq,eye(p),p+2,de.meaned = T)
}
cov.shrink.pm = function(S,S0,nu,
de.meaned = F){
## Evaluate posterior mean from following hierarchical model:
# Y ~ N_(nxp)(0,Sig)
# Therefore, S = Y'Y ~ W(Sig,n)
# Sig ~ IW(S0^(-1)/(nu-p-1),nu)
# if de.meaned = true, use n-1 instead of n in degrees of freedom on S
nu.star = nu + n
if ( de.meaned == T ){
nu.star = nu.star - 1
}
out = (S0 * (nu - p - 1) + S)/(nu.star - p - 1)
return(out)
}
cov.shrink.pm = function(S,n,S0,nu,
de.meaned = F){
## Evaluate posterior mean from following hierarchical model:
# Y ~ N_(nxp)(0,Sig)
# Therefore, S = Y'Y ~ W(Sig,n)
# Sig ~ IW(S0^(-1)/(nu-p-1),nu)
# if de.meaned = true, use n-1 instead of n in degrees of freedom on S
nu.star = nu + n
if ( de.meaned == T ){
nu.star = nu.star - 1
}
out = (S0 * (nu - p - 1) + S)/(nu.star - p - 1)
return(out)
}
###########################
## no pooling- shrink to decent prior/regularization
df = p + 4
for ( j in 1:g){
nopool.collect[,,j] = cov.shrink.pm(sumsq,ns[j],eye(p),p+2,de.meaned = T)
}
output$nopool = nopool.collect
for ( j in 1:g){
sumsq = t(Y.list[[j]]) %*% Y.list[[j]]
nopool.collect[,,j] = cov.shrink.pm(sumsq,ns[j],eye(p),p+2,de.meaned = T)
}
output$nopool = nopool.collect
###########################
## kron MLE- hetero
kron.out = lapply(Y.list,function(j)
cov.kron.mle(vec.inv.array(j,p1,p2), de.meaned = TRUE))
kron.out = lapply(kron.out,function(j)kronecker(j$Sigma,j$Psi))
output$hetero.kron = list.to.3d.array(kron.out)
###########################
## kron MLE- homo
temp = cov.kron.pool.mle(Y.array,group, de.meaned = TRUE)
kron.homo.out = kronecker(temp$Sigma,temp$Psi)
###########################
## kron MLE- homo
temp = cov.kron.pool.mle(Y.array,group, de.meaned = TRUE)
cov.kron.pool.mle = function(X,group,itmax = 100,eps = 1e-5,
de.meaned = F){
## block coordinate descent algorithm
## X: p1 x p2 x n array
## output: Psi p1 x p1 row covariance
## output: Sig p2 x p2 column covariance
# if de.meaned = true, use n-1 instead of n in degrees of freedom on observed data sampling distn
# params
group = as.factor(group)
p1 = dim(X)[1]
p2 = dim(X)[2]
N = dim(X)[3]; n = N
if (de.meaned == TRUE){
N = N - length(unique(group))
}
# initialize sig tilde
Sig.tilde = matrix(rowMeans(apply(X,3,cov.mle)),ncol = p2)
Sig.tilde.inv = qr.solve(Sig.tilde)
# initialize stopping checks
Psi.tilde = matrix(0,ncol = p1,nrow = p1)
check = F
it = 0
Psi.tilde.old = matrix(0,ncol = p1,nrow = p1)
Sig.tilde.old = matrix(0,ncol = p2, nrow = p2)
while((check == FALSE) & (it < itmax)){
Psi.tilde = tapply(seq_len(n),group,function(KK)
matrix(rowSums(apply(X[,,KK],3,function(MM)MM %*% Sig.tilde.inv %*% t(MM))),
ncol = p1)
)
Psi.tilde = Reduce("+",Psi.tilde)/(N*p2)
Psi.tilde.inv = qr.solve(Psi.tilde)
Sig.tilde = tapply(seq_len(n),group,function(KK)
matrix(rowSums(apply(X[,,KK],3,function(MM)t(MM) %*% Psi.tilde.inv %*% MM)),
ncol = p2)
)
Sig.tilde = Reduce("+",Sig.tilde)/(N*p1)
Sig.tilde.inv = qr.solve(Sig.tilde)
if (all(abs(Sig.tilde.old-Sig.tilde)<eps) &
all(abs(Psi.tilde.old-Psi.tilde)<eps)){
check = TRUE
}
# update for next iteration in while loop
it = it+1
Psi.tilde.old = Psi.tilde
Sig.tilde.old = Sig.tilde
}
return(list("Psi" = Psi.tilde,"Sigma" = Sig.tilde))
}
###########################
## kron MLE- homo
temp = cov.kron.pool.mle(Y.array,group, de.meaned = TRUE)
kron.homo.out = kronecker(temp$Sigma,temp$Psi)
output$homo.kron = rep.array(kron.homo.out,g)
###########################
## homogeneous - pool
pool.out = cov.pool(Y.matrix,group)
output$pool = rep.array(pool.out,g)
###########################
## heterogeneous - standard MLE
standard.mle = tapply(seq_len(sum(ns)),group,function(KK)
cov.func(Y.matrix[KK,]))
output$mle = list.to.3d.array(standard.mle)
###########################
## get distance from each output and the truth
loss$stein = unlist(lapply(output,function(k)
mean(sapply(1:g,function(l) loss_stein(k[,,l],Sig.true[[l]] )))))
loss$quad = unlist(lapply(output,function(k)
mean(sapply(1:g,function(l) loss_quad(k[,,l],Sig.true[[l]] )))))
loss$sq = unlist(lapply(output,function(k)
mean(sapply(1:g,function(l) loss_sq(k[,,l],Sig.true[[l]] )))))
source("~/Documents/Research/multiple_shrinkage/replication_code/simulation.R", echo=TRUE)
final.out
final.out[1,1,1]
source("~/Documents/Research/multiple_shrinkage/replication_code/simulation.R", echo=TRUE)
source("~/Documents/Research/multiple_shrinkage/replication_code/simulation.R", echo=TRUE)
source("~/Documents/Research/multiple_shrinkage/replication_code/simulation.R", echo=TRUE)
source("~/Documents/Research/multiple_shrinkage/replication_code/simulation.R", echo=TRUE)
source("~/Documents/Research/multiple_shrinkage/replication_code/simulation.R", echo=TRUE)
source("~/Documents/Research/multiple_shrinkage/replication_code/simulation.R", echo=TRUE)
source("~/Documents/Research/multiple_shrinkage/replication_code/simulation.R", echo=TRUE)
source("~/Documents/Research/multiple_shrinkage/replication_code/simulation.R", echo=TRUE)
source("~/Documents/Research/multiple_shrinkage/replication_code/simulation.R", echo=TRUE)
